{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Car fuel efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = 'http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data'\n",
    "column_names = [\"MPG\",\"Cylinders\",\"Displacement\",\"Horsepower\",\"Weight\",\"Acceleration\",\"Model Year\",\"Origin\"]\n",
    "df = pd.read_csv(url,names=column_names,na_values=\"?\",comment='\\t',sep=\" \", skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows wo values\n",
    "df = df.dropna()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MPG</th>\n",
       "      <th>Cylinders</th>\n",
       "      <th>Displacement</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Acceleration</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>28.0</td>\n",
       "      <td>-0.824303</td>\n",
       "      <td>-0.901020</td>\n",
       "      <td>-0.736562</td>\n",
       "      <td>-0.950031</td>\n",
       "      <td>0.255202</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>19.4</td>\n",
       "      <td>0.351127</td>\n",
       "      <td>0.413800</td>\n",
       "      <td>-0.340982</td>\n",
       "      <td>0.293190</td>\n",
       "      <td>0.548737</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.526556</td>\n",
       "      <td>1.144256</td>\n",
       "      <td>0.713897</td>\n",
       "      <td>1.339617</td>\n",
       "      <td>-0.625403</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>30.5</td>\n",
       "      <td>-0.824303</td>\n",
       "      <td>-0.891280</td>\n",
       "      <td>-1.053025</td>\n",
       "      <td>-1.072585</td>\n",
       "      <td>0.475353</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>14.0</td>\n",
       "      <td>1.526556</td>\n",
       "      <td>1.563051</td>\n",
       "      <td>1.636916</td>\n",
       "      <td>1.470420</td>\n",
       "      <td>-1.359240</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MPG  Cylinders  Displacement  Horsepower    Weight  Acceleration  \\\n",
       "203  28.0  -0.824303     -0.901020   -0.736562 -0.950031      0.255202   \n",
       "255  19.4   0.351127      0.413800   -0.340982  0.293190      0.548737   \n",
       "72   13.0   1.526556      1.144256    0.713897  1.339617     -0.625403   \n",
       "235  30.5  -0.824303     -0.891280   -1.053025 -1.072585      0.475353   \n",
       "37   14.0   1.526556      1.563051    1.636916  1.470420     -1.359240   \n",
       "\n",
       "     Model Year  Origin  \n",
       "203          76       3  \n",
       "255          78       1  \n",
       "72           72       1  \n",
       "235          77       1  \n",
       "37           71       1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train/test splits\n",
    "import sklearn\n",
    "import sklearn.model_selection\n",
    "from pandas import DataFrame\n",
    "from typing import Tuple\n",
    "split: Tuple[DataFrame,DataFrame] = sklearn.model_selection.train_test_split(df,train_size=0.8,random_state=1)\n",
    "df_train, df_test = split\n",
    "train_stats = df_train.describe().transpose()\n",
    "\n",
    "numeric_column_names = ['Cylinders','Displacement','Horsepower','Weight','Acceleration']\n",
    "df_train_norm, df_test_norm = df_train.copy(), df_test.copy()\n",
    "df_train_norm[numeric_column_names] = df_train_norm[numeric_column_names].astype(float)\n",
    "df_test_norm[numeric_column_names] = df_test_norm[numeric_column_names].astype(float)\n",
    "for col_name in numeric_column_names:\n",
    "    mean = train_stats.loc[col_name,'mean']\n",
    "    std = train_stats.loc[col_name,'std']\n",
    "    df_train_norm.loc[:,col_name] = (df_train_norm.loc[:,col_name]-mean)/std\n",
    "    df_test_norm.loc[:,col_name] = (df_test_norm.loc[:,col_name]-mean)/std\n",
    "df_train_norm.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to group the fine-grained model year information, into buckets, assigning each car into one of four\n",
    "year buckets, as follows:\n",
    "$$bucket=\\begin{cases}\n",
    "    0 \\text{ if }year < 73 \\\\\n",
    "    1 \\text{ if }73 \\leq year < 76 \\\\\n",
    "    2 \\text{ if }76 \\leq year < 79 \\\\\n",
    "    3 \\text{ if }year \\geq 79 \\\\\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "boundaries = torch.tensor([73,76,79])\n",
    "v = torch.tensor(df_train_norm['Model Year'].values)\n",
    "df_train_norm['Model Year Bucketed'] = torch.bucketize(v,boundaries,right=True) # The right is for inclusion or\n",
    "# exclusion from an interval if a value is on the threshold.\n",
    "v = torch.tensor(df_test_norm['Model Year'].values)\n",
    "df_test_norm['Model Year Bucketed'] = torch.bucketize(v,boundaries,right=True) # The right is for inclusion or\n",
    "numeric_column_names.append('Model Year Bucketed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a categorical approach we can choose between encoding categories in one-hot-encoded vectors, or to use \n",
    "`nn.Embedding` to convert each category in a dense vector of floats (the `nn.Embedding` can be trained, and it's optimal\n",
    "for use cases with many different categories)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will use one-hot-encoding\n",
    "from torch.nn.functional import one_hot\n",
    "total_origin = len(set(df_train_norm['Origin']))\n",
    "origin_encoded = one_hot(torch.from_numpy(df_train_norm['Origin'].values)%total_origin)\n",
    "x_train_numeric = torch.tensor(df_train_norm[numeric_column_names].values)\n",
    "x_train = torch.cat((x_train_numeric,origin_encoded),1).float()\n",
    "origin_encoded = one_hot(torch.from_numpy(df_test_norm['Origin'].values)%total_origin)\n",
    "x_test_numeric = torch.tensor(df_test_norm[numeric_column_names].values)\n",
    "x_test = torch.cat((x_test_numeric,origin_encoded),1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating label tensors\n",
    "y_train = torch.tensor(df_train_norm[\"MPG\"].values).float()\n",
    "y_test = torch.tensor(df_test_norm[\"MPG\"].values).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a DNN regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "train_ds = TensorDataset(x_train,y_train)\n",
    "batch_size = 8\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(train_ds,batch_size,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=9, out_features=8, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=4, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# Creating the model\n",
    "hidden_units = [8, 4]\n",
    "input_size = x_train.shape[1]\n",
    "all_layers = []\n",
    "for hidden_unit in hidden_units:\n",
    "    all_layers.append(nn.Linear(input_size,hidden_unit))\n",
    "    all_layers.append(nn.ReLU())\n",
    "    input_size = hidden_unit\n",
    "\n",
    "all_layers.append(nn.Linear(hidden_units[-1],1))\n",
    "model = nn.Sequential(*all_layers)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "num_epochs = 200\n",
    "log_epochs = 20\n",
    "model = model.to(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss 536.1047\n",
      "Epoch 20 Loss 8.4361\n",
      "Epoch 40 Loss 7.8695\n",
      "Epoch 60 Loss 7.1891\n",
      "Epoch 80 Loss 6.7062\n",
      "Epoch 100 Loss 6.7599\n",
      "Epoch 120 Loss 6.3124\n",
      "Epoch 140 Loss 6.6864\n",
      "Epoch 160 Loss 6.7648\n",
      "Epoch 180 Loss 6.2156\n"
     ]
    }
   ],
   "source": [
    "# Training cycle\n",
    "for epoch in range(num_epochs):\n",
    "    loss_hist_train = 0\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        x_batch, y_batch = x_batch.to(\"mps\"), y_batch.to(\"mps\") \n",
    "        pred: torch.Tensor = model(x_batch)[:,0] # Used to have a flat vector (not a rank-1 vector)\n",
    "        loss: torch.Tensor = loss_fn(pred,y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_hist_train += loss.item()\n",
    "    if epoch % log_epochs == 0:\n",
    "        print(f'Epoch {epoch} Loss {loss_hist_train/len(train_dl):.4f}')\n",
    "        # The length of train dl is the length of the dataset devided by the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 9.6130\n",
      "Test MAE: 2.1211\n"
     ]
    }
   ],
   "source": [
    "# Testing on the test dataset\n",
    "with torch.no_grad():\n",
    "    pred = model(x_test.float().to(\"mps\"))[:,0]\n",
    "    loss = loss_fn(pred,y_test.to(\"mps\"))\n",
    "    print(f'Test MSE: {loss.item():.4f}')\n",
    "    print(f'Test MAE: {nn.L1Loss()(pred,y_test.to(\"mps\")).item():.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
