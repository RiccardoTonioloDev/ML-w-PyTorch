{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Character-level language modeling in PyTorch\n",
    "\n",
    "In the model that we will build now, the input is a text document, and our goal is to develop a model that can generate\n",
    "new text that is similar in style to the input document.\n",
    "\n",
    "In character-level language modeling, the input is broken down into a sequence of characters that are fed into our\n",
    "network one character at a time. The network will process each new character in conjunction with the memory of the\n",
    "previously seen characters to predict the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1144k  100 1144k    0     0  1606k      0 --:--:-- --:--:-- --:--:-- 1606k\n"
     ]
    }
   ],
   "source": [
    "# Downloading the dataset\n",
    "!curl -O https://raw.githubusercontent.com/rasbt/machine-learning-book/refs/heads/main/ch15/1268-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total length: 1112350\n",
      "Unique charcters: 80\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the dataset\n",
    "import numpy as np\n",
    "with open('1268-0.txt','r',encoding='utf-8') as fp:\n",
    "    text = fp.read()\n",
    "start_idx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_idx:end_indx]\n",
    "char_set = set(text)\n",
    "print(f\"Total length: {len(text)}\")\n",
    "print(f\"Unique charcters: {len(char_set)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need a way to convert characters into integer values and vice-versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS  ===> [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28] ===> ISLAND\n"
     ]
    }
   ],
   "source": [
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i,ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "text_encoded = np.array([char2int[ch] for ch in text],dtype=np.int32)\n",
    "print(text[:15],\"===>\",text_encoded[:15])\n",
    "print(text_encoded[15:21],\"===>\",\"\".join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal now is to design a model that can predict the next character of a given input sequence, where the input\n",
    "sequence represents an incomplete text. This problem can be thinked of as a multiclass classification task.\n",
    "\n",
    "Let's firstly clip the sequence length to 40. In practice, the sequence length impacts the quality of the generated\n",
    "text. Longer sequences can result in more meaningful sentences. For shorter sequences, however, the model might focus\n",
    "on capturing individual words correctly, while ignoring the context for the most part.\n",
    "\n",
    "Thus, in practice, finding a sweet spot and good value for the sequence length is a hyperparameter optimization problem,\n",
    "which we have to evaluate empirically. (In this specific case 40 offers a good tradeoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8q/dn061sy56s7b4yfppcpnhkqc0000gn/T/ipykernel_19106/2539525735.py:18: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:277.)\n",
      "  seq_dataset = TextDataset(torch.tensor(text_chunks))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "seq_length = 40\n",
    "chunk_size = seq_length+1\n",
    "text_chunks = [text_encoded[i:i+chunk_size] for i in range(len(text_encoded)-chunk_size+1)]\n",
    "from torch.utils.data import Dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, text_chunks):\n",
    "        self.text_chunks = text_chunks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_chunks)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text_chunk = self.text_chunks[index]\n",
    "        return text_chunk[:-1].long(), text_chunk[1:].long()\n",
    "\n",
    "seq_dataset = TextDataset(torch.tensor(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Input (x):  'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
      "Tartet (y):  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "\n",
      " Input (x):  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "Tartet (y):  'E MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by '\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, (seq,target) in enumerate(seq_dataset):\n",
    "    print(' Input (x): ',repr(\"\".join(char_array[seq])))\n",
    "    print('Tartet (y): ',repr(\"\".join(char_array[target])))\n",
    "    print()\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "seq_dl = DataLoader(seq_dataset,batch_size,shuffle=True,drop_last=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
