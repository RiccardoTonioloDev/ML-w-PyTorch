{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "IMDB_df = pd.read_csv('../Sentiment analysis/movie_data.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import random_split\n",
    "training_dataset, test_dataset = random_split(IMDB_df.values, [25000,25000])\n",
    "train_dataset, valid_dataset = random_split(training_dataset,[20000,5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\W'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\)'\n",
      "<>:8: SyntaxWarning: invalid escape sequence '\\W'\n",
      "/var/folders/8q/dn061sy56s7b4yfppcpnhkqc0000gn/T/ipykernel_18113/2767876497.py:6: SyntaxWarning: invalid escape sequence '\\)'\n",
      "  emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text.lower())\n",
      "/var/folders/8q/dn061sy56s7b4yfppcpnhkqc0000gn/T/ipykernel_18113/2767876497.py:8: SyntaxWarning: invalid escape sequence '\\W'\n",
      "  re.sub('[\\W]+',' ',text.lower()) + # removed all non-word characters from the text\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab-size: 70831\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "def tokenizer(text):\n",
    "    text = re.sub('<[^>]*>','',text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text.lower())\n",
    "    text = (\n",
    "        re.sub('[\\W]+',' ',text.lower()) + # removed all non-word characters from the text\n",
    "        ' '.join(emoticons) # added found emoticons at the end of the screen\n",
    "            .replace('-','') # removed the nose from faces for consistency\n",
    "    )\n",
    "    tokenized = text.split()\n",
    "    return tokenized\n",
    "\n",
    "token_counts = Counter()\n",
    "for line, label in train_dataset:\n",
    "    tokens = tokenizer(line)\n",
    "    token_counts.update(tokens)\n",
    "print('Vocab-size:',len(token_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riccardotoniolo/miniconda3/envs/mllib/lib/python3.12/site-packages/torchtext/vocab/__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "/Users/riccardotoniolo/miniconda3/envs/mllib/lib/python3.12/site-packages/torchtext/utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "from torchtext.vocab import vocab\n",
    "sorted_by_freq_tuples = sorted(token_counts.items(),key=lambda x: x[1],reverse=True)\n",
    "ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
    "vocab = vocab(ordered_dict)\n",
    "vocab.insert_token(\"<pad>\",0)\n",
    "vocab.insert_token(\"<unk>\",1) # Unknown token, used to map not seen tokens\n",
    "vocab.set_default_index(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11, 7, 35, 468]\n"
     ]
    }
   ],
   "source": [
    "print([vocab[token] for token in ['this','is','an','example']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 6878,  6417, 16755,  ...,   456,     6,   132],\n",
      "        [   15,    18,    31,  ...,     0,     0,     0],\n",
      "        [   52,     7,   243,  ...,     0,     0,     0],\n",
      "        [   11,     7,    29,  ...,     0,     0,     0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list, lengths = [], [], []\n",
    "    for _text, _label in batch:\n",
    "        label_list.append(_label)\n",
    "        processed_text = torch.tensor(text_pipeline(_text),dtype=torch.int64)\n",
    "        text_list.append(processed_text)\n",
    "        lengths.append(processed_text.size(0))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    lengths = torch.tensor(lengths)\n",
    "    padded_text_list = nn.utils.rnn.pad_sequence(text_list,batch_first=True) # this is done so that the batch has the\n",
    "    # same width on every phrase, using \"<pad>\" tokens to pad (that were previously inseted in the vocab object, and\n",
    "    # associated with the 0 value).\n",
    "    return padded_text_list, label_list, lengths\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "dataloader = DataLoader(train_dataset,batch_size=4,shuffle=False,collate_fn=collate_batch)\n",
    "\n",
    "text_batch, label_batch, length_batch = next(iter(dataloader))\n",
    "print(text_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_dl = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,collate_fn=collate_batch)\n",
    "valid_dl = DataLoader(valid_dataset,batch_size=BATCH_SIZE,shuffle=False,collate_fn=collate_batch)\n",
    "test_dl = DataLoader(test_dataset,batch_size=BATCH_SIZE,shuffle=False,collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset is fully preprocessed for a RNN to be trained on it.\n",
    "\n",
    "## Embedding layers for sentence encoding\n",
    "\n",
    "The elements of the sequences are integer numbers that correponded to the indices of unique words. These word indices\n",
    "can be converted into input features in several different ways. One naive way is to apply one-hot encoding to convert \n",
    "the indicesinto vectors of zeros and ones. Then, each word will be mapped to avector whose size is the number of unique\n",
    "words in the entire dataset.\n",
    "\n",
    "The number of words is in the order of 1k to 10k, which will also be the number of our input features. A model trained\n",
    "on such features may suffer from the curse of dimensionality (furthermore the features are very sparse).\n",
    "\n",
    "A more elegant approach is to map each word to a vector of fixed size with real-valued elements. In contrast to the\n",
    "one-hot encoded vectors, we can use finite-sized vectors to represent an infinite number of real numbers. That's the\n",
    "idea behind embedding.\n",
    "\n",
    "Given the number of unique words, $n_{words}$, we can select the size of the embedding vectors, to be much smaller than\n",
    "the number of unique words to represent the entire vocabulary as input features.\n",
    "\n",
    "We'll obtain:\n",
    "- A reduction in the dimensionality of the feature space to decrease the effect of the curse of dimensionality;\n",
    "- The extraction of salient features since the embedding layer in an NN can be optimized (learned).\n",
    "\n",
    "Given a set of tokens of size $n+2$, an embedding matrix of size $(n+2)\\times embedding_dim$ will be created, where each\n",
    "row in this matrix represents numeric features associated with a token. Therefore, when an integer index, $i$ is given\n",
    "as input to the embedding, it will look up the corresponding row of the meatrix at index $i$ and return the numeric\n",
    "features.\n",
    "\n",
    "Notice that the padding token, is mapped by the embedding layer to 0s, since it doesn't have to participate in the\n",
    "update of the gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.7001,  1.4577,  1.8792],\n",
      "         [ 1.9282, -2.3362, -0.5040],\n",
      "         [-0.6216,  1.4128,  0.8940],\n",
      "         [-0.0623,  0.3325,  0.2359]],\n",
      "\n",
      "        [[-0.0623,  0.3325,  0.2359],\n",
      "         [-0.6216,  1.4128,  0.8940],\n",
      "         [ 1.9282, -2.3362, -0.5040],\n",
      "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(\n",
    "    num_embeddings=10,\n",
    "    embedding_dim=3,\n",
    "    padding_idx=0\n",
    ")\n",
    "\n",
    "text_encoded_input = torch.LongTensor([[1,2,3,4],[4,3,2,0]])\n",
    "print(embedding(text_encoded_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an RNN model for the sentiment analysis task\n",
    "\n",
    "The `torch.nn` module provides many RNN implementations like: `nn.RNN`,`nn.GRU` and `nn.LSTM`.\n",
    "\n",
    "Now let's build a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,vocab_size, embed_dim, rnn_hidden_size,fc_hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size,embed_dim,padding_idx=0,)\n",
    "        self.rnn = nn.LSTM(embed_dim,rnn_hidden_size,batch_first=True)\n",
    "        self.fc1 = nn.Linear(rnn_hidden_size,fc_hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(fc_hidden_size,1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,text,lengths):\n",
    "        out = self.embedding(text)\n",
    "        out = nn.utils.rnn.pack_padded_sequence(out,lengths.to(\"cpu\"),enforce_sorted=False,batch_first=True)\n",
    "        out, (hidden,cell) = self.rnn(out)\n",
    "        out = hidden[-1,:,:]\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(vocab)\n",
    "EMBDED_DIM = 20\n",
    "RNN_HIDDEN_SIZE = 64\n",
    "FC_HIDDEN_SIZE = 64\n",
    "torch.manual_seed(1)\n",
    "model = RNN(VOCAB_SIZE,EMBDED_DIM,RNN_HIDDEN_SIZE,FC_HIDDEN_SIZE).to(\"mps\")\n",
    "optimizer = torch.optim.Adam(model.parameters(), 0.001)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    model.train()\n",
    "    total_acc, total_loss = 0,0\n",
    "    for text_batch, label_batch, lengths in dataloader:\n",
    "        text_batch, label_batch, lengths = text_batch.to(\"mps\"), label_batch.to(\"mps\"), lengths.to(\"mps\")\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(text_batch, lengths)[:,0]\n",
    "        loss = loss_fn(pred,label_batch.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "        total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader):\n",
    "    model.eval()\n",
    "    total_acc, total_loss = 0,0\n",
    "    with torch.no_grad():\n",
    "        for text_batch, label_batch, lengths in dataloader:\n",
    "            text_batch, label_batch, lengths = text_batch.to(\"mps\"), label_batch.to(\"mps\"), lengths.to(\"mps\")\n",
    "            pred = model(text_batch, lengths)[:,0]\n",
    "            loss = loss_fn(pred,label_batch.float())\n",
    "            total_acc += ((pred>=0.5).float() == label_batch).float().sum().item()\n",
    "            total_loss += loss.item()*label_batch.size(0)\n",
    "    return total_acc/len(dataloader.dataset), total_loss/len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 accuracy: 0.6106 val_accuracy: 0.6546\n",
      "Epoch 1 accuracy: 0.7231 val_accuracy: 0.7592\n",
      "Epoch 2 accuracy: 0.8064 val_accuracy: 0.8100\n",
      "Epoch 3 accuracy: 0.8511 val_accuracy: 0.8358\n",
      "Epoch 4 accuracy: 0.8728 val_accuracy: 0.8266\n",
      "Epoch 5 accuracy: 0.9016 val_accuracy: 0.8538\n",
      "Epoch 6 accuracy: 0.9204 val_accuracy: 0.8528\n",
      "Epoch 7 accuracy: 0.9375 val_accuracy: 0.8540\n",
      "Epoch 8 accuracy: 0.9375 val_accuracy: 0.8598\n",
      "Epoch 9 accuracy: 0.9572 val_accuracy: 0.8592\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(num_epochs):\n",
    "    acc_train, loss_train = train(train_dl)\n",
    "    acc_valid, loss_valid = evaluate(valid_dl)\n",
    "    print(f'Epoch {epoch} accuracy: {acc_train:.4f} val_accuracy: {acc_valid:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accuracy: 0.8458\n"
     ]
    }
   ],
   "source": [
    "acc_test, _ = evaluate(test_dl)\n",
    "print(f'test_accuracy: {acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exist even bidirectional RNNs, that do a farward pass and a backward pass trough the input. The hidden states of\n",
    "the two passes are then concatenated or merged with a product, sum or average."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
