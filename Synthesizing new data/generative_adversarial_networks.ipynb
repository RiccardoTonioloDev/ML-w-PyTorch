{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Introducing generative models for synthesizing new data;\n",
    "- Autoencoders, variational autoencoders, and their relationship to GANs;\n",
    "- Understanding he building blocks of GANs;\n",
    "- Implementing a simple GAN model to generate handwritten digits;\n",
    "- Understanding transposed convolution and batch normalization;\n",
    "- Improving GANs: deep convolutional GANs and GANs using the Wasserstein distance.\n",
    "\n",
    "# Introducing generative adversarial networks\n",
    "\n",
    "The overall objective of a GAN is to synthesize new data that has the same distribution as its training dataset. They \n",
    "are considered to be in the unsupervised learning category of machine learning tasks, since no labeled data is required.\n",
    "\n",
    "While the original GAN architecture proposed in this paper was based on fully connected layers, similar to multilayer\n",
    "perceptron architectures, and trained to generate low-resolution MNIST-like handwritten digits, it served more as a\n",
    "proof of concept to demonstrate the feasibility of this new approach.\n",
    "\n",
    "# Starting with autoencoders\n",
    "\n",
    "While standard autoencoders cannot generate new data, understanding their function will help you better understand GANs.\n",
    "\n",
    "Autoencoders are composed of two networks concatenated together: an encoder network and a decoder network. The encoder\n",
    "network receives a $d$ dimensional input feature vector associated with example $x$ and encodes it into a $p$\n",
    "dimensional vector $z$. In other words, the role of the encoder is to learn how to model the function $z = f(x)$.\n",
    "\n",
    "The encoded vector, $z$, is also called the latent vector, or the latent feature representation. Typically, the\n",
    "dimensionality of the latent vector is less than that of the input examples ($p<d$). Hence, we can say that the encoder\n",
    "acts as a data compression function.\n",
    "\n",
    "Then, the encoder decompresses $\\hat{x}$ from the lower-dimensional latent vector, $z$, where we can thing of the\n",
    "encoder as a function $\\hat{x}=g(z)$.\n",
    "\n",
    "> Notice that there are variants of autoencoders that use a latent space of bigger dimensionality compared to the\n",
    "> dimensionality of the input. This is especially usefull in the context of de-noising.\n",
    "\n",
    "# Generative model for synthesizing new data\n",
    "Autoencoders are deterministic models, so they are just able to reconstruct an image from its latent feature\n",
    "representation. They are not able to generate data beyound reconstructing its input through the transformation of the\n",
    "compressed representation.\n",
    "\n",
    "A generative model, on the other hand, can generate a new example, $\\~x$, from a random vector, $z$ (corresponding to\n",
    "the latent representation).\n",
    "\n",
    "We can notice some similarities between the decoder of the autoencoder and a generative model. However a major\n",
    "difference between the two is that we do not know the distribution of $z$ in the autoencoder, while in the generative\n",
    "model, the distribution of $z$ is fully characterizable. One approach to generalize an autoencoder int oa generative\n",
    "model is the variational autoencoder (VAE).\n",
    "\n",
    "In a VAE receiving an input example, $x$, the encoder network is modified in such a way that it computes two moments of\n",
    "the distribution of the latent vector: the mean, $\\mu$ and the variance $\\sigma^2$. During the training of a VAE, the\n",
    "network is forced to match these moments with those of a standard normal distribution (zero mean and unit variance).\n",
    "Then, after the VAE model is trained, the encoder is discarded and we can use the decoder network to generate new\n",
    "examples, $\\~x$, by feeding random $z$ vectors from the \"learned\" gaussian distribution.\n",
    "\n",
    "# Generating new samples with GANs\n",
    "\n",
    "Let's assume we have a network generator $G$ so that $\\~x = G(z)$, where $z$ is a random vector, sampled from a known\n",
    "ditribution. As always, we will initialize this network with random weights. Therefore, the first output images, before\n",
    "the weights are adjusted, will look like white noise.\n",
    "\n",
    "Now, imagine there is a function that can assess the quality of images (assessor function). We can use the feedback from\n",
    "that function to tell our generator network how to adjust its weights to improve the quality of the generated images.\n",
    "\n",
    "While an assessor function, as described in the previous paragraph, would make the image generation task very easy, the\n",
    "question is whether such a universal function to assess the quality of images exists and how it is defined.\n",
    "\n",
    "GAN model consists of an additional NNcalled discriminator (D), which is a classifier that learns to detect a\n",
    "synthesized image, $\\~x$, from a real image $x$.\n",
    "\n",
    "In a GAN model, the two networks, generator and discriminator, are trained together. Over time, both networks become\n",
    "better as they interact with each other. In fact, the two networks play an adversarial game, where the generator learns\n",
    "to improve its output to be able to fool the discriminator. At the same time, the discriminator becomes better at\n",
    "detecting the synthesized images.\n",
    "\n",
    "## Understanding the loss function of the generator and discriminator networks in a GAN model\n",
    "$$\n",
    "V(\\theta^{(D)},\\theta^{(G)}) = E_{x~p_{data}(x)}[\\log{D(x)}] + E_{z~p_z(z)}[\\log{(1-D(G(z)))}]\n",
    "$$\n",
    "\n",
    "Here, $V(\\theta^{(D)},\\theta^{(G)})$ is called the value function, which can be interpreted as a payoff: we want to\n",
    "maximize its value with respect to the discriminator, while minimizing its value with respect to the generator.\n",
    "\n",
    "$D(x)$ is the probability that indicates whether the input example, $x$ (that is generated), is real or fake.\n",
    "\n",
    "The expression $E_{x~p_{data}(x)}[\\log{D(x)}]$ refers to the expected value (averaging though all the samples) of the\n",
    "quantity in brackets with respect to the examples from the data distribution (distribution of the real examples).\n",
    "$E_{z~p_z(z)}[\\log{(1-D(G(z)))}]$ refers to the expected value of the quantity with respect to the distribution of the\n",
    "input, $z$, vectors.\n",
    "\n",
    "A practical way of training GANs is to alternate between these two optimization steps:\n",
    "1. Freeze the parameters of one network and optimie the weights of the other one;\n",
    "2. Freeze the second network and optimize the first one;\n",
    "3. Repeat at each training iteration.\n",
    "\n",
    "Let's assume that the generator network is fixed, and we want to optimize the discriminator. Both terms in the value\n",
    "function contribute to optimizing the discriminator, where the first term corresponds to the loss associated with the\n",
    "real examples, and the second term is the loss for the fake examples.\n",
    "\n",
    "Therefore, when $G$ is fixed, our objective is to maximize the value function, which means making the discriminator\n",
    "better at distinguishing between real and generated images.\n",
    "\n",
    "After optimizing the discriminator using the loss terms for real and fake samples, we then fix the discriminator and\n",
    "optimize the generator. In this case, only the second term of the value function contributes to the gradients of the\n",
    "generator. As a result, when $D$ is fixed, our objective is to minimize the value function.\n",
    "\n",
    "However, $\\log{(1-D(G(z)))}$ suffers from vanishing gradients in the early training stages (early in the learning\n",
    "process generated outputs look nothing like real examples, therefore, $D(G(z))$ will be close to zero). This phenomenon\n",
    "is called saturation. To resolve this issue, we can reformulate the maximization objective to the minimization of\n",
    "$E_{z~p_z(z)}[\\log{(D(G(z)))}]$. If we are using this technique we have to swap the labels of real and fake examples (1\n",
    "will be assigned to fake images, 0 otherwise).\n",
    "\n",
    "## Implementing a GAN from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_generator_network(input_size = 20, num_hidden_layers = 1, num_hidden_units = 100,  num_output_units = 784):\n",
    "    model = nn.Sequential()\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add_module(f\"hidden{i}\",nn.Sequential(\n",
    "            nn.Linear(input_size,num_hidden_units),\n",
    "            nn.LeakyReLU(),\n",
    "        ))\n",
    "        input_size = num_hidden_units\n",
    "    model.add_module(\"prediction_head\",nn.Sequential(\n",
    "        nn.Linear(input_size,num_output_units),\n",
    "        nn.Tanh()\n",
    "    ))\n",
    "    return model\n",
    "\n",
    "def make_discriminator_network(input_size, num_hidden_layers = 1, num_hidden_units = 100,  num_output_units = 1):\n",
    "    model = nn.Sequential()\n",
    "    for i in range(num_hidden_layers):\n",
    "        model.add_module(f\"hidden{i}\",nn.Sequential(\n",
    "            nn.Linear(input_size,num_hidden_units),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout()\n",
    "        ))\n",
    "        input_size = num_hidden_units\n",
    "    model.add_module(\"prediction_head\",nn.Sequential(\n",
    "        nn.Linear(input_size,num_output_units),\n",
    "        nn.Sigmoid()\n",
    "    ))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (28,28)\n",
    "z_size = 20\n",
    "gen_hidden_layers = 1\n",
    "gen_hidden_size = 100\n",
    "disc_hidden_layers = 1\n",
    "disc_hidden_size = 100\n",
    "\n",
    "import torch\n",
    "torch.manual_seed(1)\n",
    "gen_model = make_generator_network(z_size,gen_hidden_layers,gen_hidden_size,np.prod(image_size))\n",
    "disc_model = make_discriminator_network(np.prod(image_size),disc_hidden_layers,disc_hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms.v2 as t\n",
    "image_path = '../NNs with PyTorch/'\n",
    "transform = t.Compose([\n",
    "    t.ToImage(),\n",
    "    t.ToDtype(torch.float32,scale=True),\n",
    "    t.Normalize(mean=[0.5],std=[0.5])\n",
    "])\n",
    "mnist_dataset = torchvision.datasets.MNIST(root=image_path,train=True,transform=transform,download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noise(batch_size, z_size, mode_z):\n",
    "    if mode_z == 'uniform':\n",
    "        input_z = torch.rand(batch_size,z_size)*2 - 1\n",
    "    elif mode_z == \"normal\":\n",
    "        input_z = torch.randn(batch_size,z_size)\n",
    "    return input_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "device = \"mps\"\n",
    "mnist_dl = DataLoader(\n",
    "    mnist_dataset, batch_size=batch_size, shuffle=True, drop_last=True\n",
    ")\n",
    "gen_model = make_generator_network(\n",
    "    input_size=z_size,\n",
    "    num_hidden_layers=gen_hidden_layers,\n",
    "    num_hidden_units=gen_hidden_size,\n",
    "    num_output_units=np.prod(image_size),\n",
    ").to(device)\n",
    "disc_model = make_discriminator_network(\n",
    "    input_size=np.prod(image_size),\n",
    "    num_hidden_layers=disc_hidden_layers,\n",
    "    num_hidden_units=disc_hidden_size,\n",
    ").to(device)\n",
    "loss_fn = nn.BCELoss()\n",
    "g_optimizer = torch.optim.Adam(gen_model.parameters())\n",
    "d_optimizer = torch.optim.Adam(disc_model.parameters())\n",
    "mode_z = \"uniform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_train(x):\n",
    "    disc_model.zero_grad()\n",
    "\n",
    "    # Train discriminator with a real batch\n",
    "    batch_size = x.size(0)\n",
    "    x = x.view(batch_size, -1).to(device)\n",
    "    d_labels_real = torch.ones(batch_size, 1, device=device)\n",
    "\n",
    "    d_proba_real = disc_model(x)\n",
    "    d_loss_real = loss_fn(d_proba_real, d_labels_real)\n",
    "\n",
    "    # Train discriminator on a fake batch\n",
    "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "    g_output = gen_model(input_z)\n",
    "\n",
    "    d_proba_fake = disc_model(g_output)\n",
    "    d_labels_fake = torch.zeros(batch_size, 1, device=device)\n",
    "    d_loss_fake = loss_fn(d_proba_fake, d_labels_fake)\n",
    "\n",
    "    # gradient backprop & optimize ONLY D's parameters\n",
    "    d_loss = d_loss_real + d_loss_fake\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "\n",
    "    return d_loss.data.item(), d_proba_real.detach(), d_proba_fake.detach()\n",
    "\n",
    "\n",
    "def g_train(x):\n",
    "    gen_model.zero_grad()\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    input_z = create_noise(batch_size, z_size, mode_z).to(device)\n",
    "    g_labels_real = torch.ones(batch_size, 1, device=device)\n",
    "\n",
    "    g_output = gen_model(input_z)\n",
    "    d_proba_fake = disc_model(g_output)\n",
    "    g_loss = loss_fn(d_proba_fake, g_labels_real)\n",
    "\n",
    "    # gradient backprop & optimize ONLY G's parameters\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "\n",
    "    return g_loss.data.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001 | Avg Losses >> G/D 1.4675/0.5866 [D-Real: 0.8773 D-Fake: 0.3288]\n",
      "Epoch 002 | Avg Losses >> G/D 0.8591/1.1609 [D-Real: 0.6106 D-Fake: 0.4532]\n",
      "Epoch 003 | Avg Losses >> G/D 1.1555/1.0438 [D-Real: 0.6454 D-Fake: 0.3814]\n",
      "Epoch 004 | Avg Losses >> G/D 0.9994/1.1473 [D-Real: 0.5993 D-Fake: 0.4003]\n",
      "Epoch 005 | Avg Losses >> G/D 1.0814/1.1487 [D-Real: 0.6015 D-Fake: 0.3959]\n",
      "Epoch 006 | Avg Losses >> G/D 1.0299/1.1625 [D-Real: 0.5965 D-Fake: 0.4001]\n",
      "Epoch 007 | Avg Losses >> G/D 1.0570/1.1688 [D-Real: 0.5965 D-Fake: 0.3988]\n",
      "Epoch 008 | Avg Losses >> G/D 1.0057/1.1898 [D-Real: 0.5879 D-Fake: 0.4105]\n",
      "Epoch 009 | Avg Losses >> G/D 1.0240/1.1773 [D-Real: 0.5925 D-Fake: 0.4045]\n",
      "Epoch 010 | Avg Losses >> G/D 1.0201/1.1883 [D-Real: 0.5897 D-Fake: 0.4086]\n",
      "Epoch 011 | Avg Losses >> G/D 1.0036/1.1658 [D-Real: 0.5987 D-Fake: 0.4063]\n",
      "Epoch 012 | Avg Losses >> G/D 1.0372/1.1803 [D-Real: 0.5950 D-Fake: 0.4065]\n",
      "Epoch 013 | Avg Losses >> G/D 1.0200/1.1680 [D-Real: 0.5986 D-Fake: 0.4056]\n",
      "Epoch 014 | Avg Losses >> G/D 0.9264/1.2373 [D-Real: 0.5688 D-Fake: 0.4306]\n",
      "Epoch 015 | Avg Losses >> G/D 0.8872/1.2661 [D-Real: 0.5571 D-Fake: 0.4421]\n",
      "Epoch 016 | Avg Losses >> G/D 0.8775/1.2686 [D-Real: 0.5545 D-Fake: 0.4433]\n",
      "Epoch 017 | Avg Losses >> G/D 0.8777/1.2649 [D-Real: 0.5568 D-Fake: 0.4427]\n",
      "Epoch 018 | Avg Losses >> G/D 0.8951/1.2590 [D-Real: 0.5594 D-Fake: 0.4396]\n",
      "Epoch 019 | Avg Losses >> G/D 0.8288/1.2988 [D-Real: 0.5424 D-Fake: 0.4575]\n",
      "Epoch 020 | Avg Losses >> G/D 0.8400/1.3017 [D-Real: 0.5413 D-Fake: 0.4570]\n",
      "Epoch 021 | Avg Losses >> G/D 0.8052/1.3181 [D-Real: 0.5327 D-Fake: 0.4655]\n",
      "Epoch 022 | Avg Losses >> G/D 0.8001/1.3217 [D-Real: 0.5323 D-Fake: 0.4670]\n",
      "Epoch 023 | Avg Losses >> G/D 0.8027/1.3229 [D-Real: 0.5314 D-Fake: 0.4666]\n",
      "Epoch 024 | Avg Losses >> G/D 0.8153/1.3169 [D-Real: 0.5339 D-Fake: 0.4633]\n",
      "Epoch 025 | Avg Losses >> G/D 0.8170/1.3149 [D-Real: 0.5346 D-Fake: 0.4640]\n",
      "Epoch 026 | Avg Losses >> G/D 0.7946/1.3252 [D-Real: 0.5295 D-Fake: 0.4682]\n",
      "Epoch 027 | Avg Losses >> G/D 0.7985/1.3206 [D-Real: 0.5321 D-Fake: 0.4671]\n",
      "Epoch 028 | Avg Losses >> G/D 0.8023/1.3212 [D-Real: 0.5313 D-Fake: 0.4670]\n",
      "Epoch 029 | Avg Losses >> G/D 0.8318/1.2998 [D-Real: 0.5415 D-Fake: 0.4581]\n",
      "Epoch 030 | Avg Losses >> G/D 0.8547/1.2862 [D-Real: 0.5488 D-Fake: 0.4532]\n",
      "Epoch 031 | Avg Losses >> G/D 0.8158/1.3062 [D-Real: 0.5403 D-Fake: 0.4634]\n",
      "Epoch 032 | Avg Losses >> G/D 0.8004/1.3181 [D-Real: 0.5330 D-Fake: 0.4669]\n",
      "Epoch 033 | Avg Losses >> G/D 0.7687/1.3428 [D-Real: 0.5214 D-Fake: 0.4769]\n",
      "Epoch 034 | Avg Losses >> G/D 0.7671/1.3440 [D-Real: 0.5218 D-Fake: 0.4772]\n",
      "Epoch 035 | Avg Losses >> G/D 0.7603/1.3477 [D-Real: 0.5187 D-Fake: 0.4778]\n",
      "Epoch 036 | Avg Losses >> G/D 0.7613/1.3479 [D-Real: 0.5198 D-Fake: 0.4791]\n",
      "Epoch 037 | Avg Losses >> G/D 0.7981/1.3203 [D-Real: 0.5336 D-Fake: 0.4679]\n",
      "Epoch 038 | Avg Losses >> G/D 0.7864/1.3244 [D-Real: 0.5311 D-Fake: 0.4715]\n",
      "Epoch 039 | Avg Losses >> G/D 0.8177/1.3026 [D-Real: 0.5415 D-Fake: 0.4624]\n",
      "Epoch 040 | Avg Losses >> G/D 0.8316/1.3037 [D-Real: 0.5403 D-Fake: 0.4595]\n",
      "Epoch 041 | Avg Losses >> G/D 0.7908/1.3212 [D-Real: 0.5328 D-Fake: 0.4696]\n",
      "Epoch 042 | Avg Losses >> G/D 0.7842/1.3261 [D-Real: 0.5299 D-Fake: 0.4712]\n",
      "Epoch 043 | Avg Losses >> G/D 0.7749/1.3343 [D-Real: 0.5259 D-Fake: 0.4737]\n",
      "Epoch 044 | Avg Losses >> G/D 0.7851/1.3230 [D-Real: 0.5314 D-Fake: 0.4703]\n",
      "Epoch 045 | Avg Losses >> G/D 0.7761/1.3279 [D-Real: 0.5296 D-Fake: 0.4729]\n",
      "Epoch 046 | Avg Losses >> G/D 0.8047/1.3106 [D-Real: 0.5372 D-Fake: 0.4644]\n",
      "Epoch 047 | Avg Losses >> G/D 0.8056/1.3144 [D-Real: 0.5350 D-Fake: 0.4647]\n",
      "Epoch 048 | Avg Losses >> G/D 0.7940/1.3220 [D-Real: 0.5324 D-Fake: 0.4681]\n",
      "Epoch 049 | Avg Losses >> G/D 0.7869/1.3305 [D-Real: 0.5286 D-Fake: 0.4710]\n",
      "Epoch 050 | Avg Losses >> G/D 0.7846/1.3329 [D-Real: 0.5266 D-Fake: 0.4713]\n",
      "Epoch 051 | Avg Losses >> G/D 0.7816/1.3312 [D-Real: 0.5273 D-Fake: 0.4713]\n",
      "Epoch 052 | Avg Losses >> G/D 0.7820/1.3255 [D-Real: 0.5309 D-Fake: 0.4716]\n",
      "Epoch 053 | Avg Losses >> G/D 0.7931/1.3247 [D-Real: 0.5306 D-Fake: 0.4688]\n",
      "Epoch 054 | Avg Losses >> G/D 0.7898/1.3221 [D-Real: 0.5322 D-Fake: 0.4694]\n",
      "Epoch 055 | Avg Losses >> G/D 0.7931/1.3225 [D-Real: 0.5317 D-Fake: 0.4676]\n",
      "Epoch 056 | Avg Losses >> G/D 0.8069/1.3159 [D-Real: 0.5352 D-Fake: 0.4655]\n",
      "Epoch 057 | Avg Losses >> G/D 0.8009/1.3224 [D-Real: 0.5321 D-Fake: 0.4673]\n",
      "Epoch 058 | Avg Losses >> G/D 0.7998/1.3197 [D-Real: 0.5331 D-Fake: 0.4671]\n",
      "Epoch 059 | Avg Losses >> G/D 0.8103/1.3168 [D-Real: 0.5344 D-Fake: 0.4644]\n",
      "Epoch 060 | Avg Losses >> G/D 0.8040/1.3152 [D-Real: 0.5350 D-Fake: 0.4657]\n",
      "Epoch 061 | Avg Losses >> G/D 0.7949/1.3239 [D-Real: 0.5326 D-Fake: 0.4694]\n",
      "Epoch 062 | Avg Losses >> G/D 0.8164/1.3087 [D-Real: 0.5384 D-Fake: 0.4624]\n",
      "Epoch 063 | Avg Losses >> G/D 0.7867/1.3246 [D-Real: 0.5312 D-Fake: 0.4703]\n",
      "Epoch 064 | Avg Losses >> G/D 0.7884/1.3312 [D-Real: 0.5278 D-Fake: 0.4709]\n",
      "Epoch 065 | Avg Losses >> G/D 0.7930/1.3259 [D-Real: 0.5294 D-Fake: 0.4695]\n",
      "Epoch 066 | Avg Losses >> G/D 0.8040/1.3181 [D-Real: 0.5340 D-Fake: 0.4665]\n",
      "Epoch 067 | Avg Losses >> G/D 0.8059/1.3179 [D-Real: 0.5338 D-Fake: 0.4658]\n",
      "Epoch 068 | Avg Losses >> G/D 0.8229/1.3053 [D-Real: 0.5405 D-Fake: 0.4606]\n",
      "Epoch 069 | Avg Losses >> G/D 0.8045/1.3142 [D-Real: 0.5356 D-Fake: 0.4648]\n",
      "Epoch 070 | Avg Losses >> G/D 0.7975/1.3200 [D-Real: 0.5327 D-Fake: 0.4672]\n",
      "Epoch 071 | Avg Losses >> G/D 0.8078/1.3180 [D-Real: 0.5342 D-Fake: 0.4662]\n",
      "Epoch 072 | Avg Losses >> G/D 0.8117/1.3150 [D-Real: 0.5361 D-Fake: 0.4649]\n",
      "Epoch 073 | Avg Losses >> G/D 0.8084/1.3144 [D-Real: 0.5362 D-Fake: 0.4650]\n",
      "Epoch 074 | Avg Losses >> G/D 0.8026/1.3197 [D-Real: 0.5333 D-Fake: 0.4670]\n",
      "Epoch 075 | Avg Losses >> G/D 0.8025/1.3179 [D-Real: 0.5340 D-Fake: 0.4664]\n",
      "Epoch 076 | Avg Losses >> G/D 0.8045/1.3194 [D-Real: 0.5336 D-Fake: 0.4660]\n",
      "Epoch 077 | Avg Losses >> G/D 0.7976/1.3213 [D-Real: 0.5335 D-Fake: 0.4681]\n",
      "Epoch 078 | Avg Losses >> G/D 0.8056/1.3190 [D-Real: 0.5331 D-Fake: 0.4655]\n",
      "Epoch 079 | Avg Losses >> G/D 0.7931/1.3277 [D-Real: 0.5297 D-Fake: 0.4684]\n",
      "Epoch 080 | Avg Losses >> G/D 0.7942/1.3304 [D-Real: 0.5287 D-Fake: 0.4701]\n",
      "Epoch 081 | Avg Losses >> G/D 0.7964/1.3237 [D-Real: 0.5313 D-Fake: 0.4688]\n",
      "Epoch 082 | Avg Losses >> G/D 0.7925/1.3205 [D-Real: 0.5328 D-Fake: 0.4684]\n",
      "Epoch 083 | Avg Losses >> G/D 0.8124/1.3157 [D-Real: 0.5356 D-Fake: 0.4650]\n",
      "Epoch 084 | Avg Losses >> G/D 0.8030/1.3166 [D-Real: 0.5345 D-Fake: 0.4664]\n",
      "Epoch 085 | Avg Losses >> G/D 0.8153/1.3151 [D-Real: 0.5352 D-Fake: 0.4638]\n",
      "Epoch 086 | Avg Losses >> G/D 0.8055/1.3121 [D-Real: 0.5368 D-Fake: 0.4662]\n",
      "Epoch 087 | Avg Losses >> G/D 0.8097/1.3189 [D-Real: 0.5342 D-Fake: 0.4650]\n",
      "Epoch 088 | Avg Losses >> G/D 0.8104/1.3143 [D-Real: 0.5366 D-Fake: 0.4657]\n",
      "Epoch 089 | Avg Losses >> G/D 0.8153/1.3093 [D-Real: 0.5377 D-Fake: 0.4619]\n",
      "Epoch 090 | Avg Losses >> G/D 0.8057/1.3179 [D-Real: 0.5341 D-Fake: 0.4659]\n",
      "Epoch 091 | Avg Losses >> G/D 0.8020/1.3238 [D-Real: 0.5311 D-Fake: 0.4676]\n",
      "Epoch 092 | Avg Losses >> G/D 0.8258/1.3066 [D-Real: 0.5397 D-Fake: 0.4614]\n",
      "Epoch 093 | Avg Losses >> G/D 0.8193/1.3112 [D-Real: 0.5383 D-Fake: 0.4627]\n",
      "Epoch 094 | Avg Losses >> G/D 0.8217/1.3116 [D-Real: 0.5370 D-Fake: 0.4629]\n",
      "Epoch 095 | Avg Losses >> G/D 0.8224/1.3106 [D-Real: 0.5378 D-Fake: 0.4626]\n",
      "Epoch 096 | Avg Losses >> G/D 0.7975/1.3207 [D-Real: 0.5327 D-Fake: 0.4672]\n",
      "Epoch 097 | Avg Losses >> G/D 0.8072/1.3175 [D-Real: 0.5347 D-Fake: 0.4658]\n",
      "Epoch 098 | Avg Losses >> G/D 0.8116/1.3159 [D-Real: 0.5343 D-Fake: 0.4641]\n",
      "Epoch 099 | Avg Losses >> G/D 0.8122/1.3177 [D-Real: 0.5347 D-Fake: 0.4653]\n",
      "Epoch 100 | Avg Losses >> G/D 0.8129/1.3152 [D-Real: 0.5365 D-Fake: 0.4649]\n"
     ]
    }
   ],
   "source": [
    "fixed_z = create_noise(batch_size,z_size,mode_z).to(device)\n",
    "def create_samples(g_model, input_z):\n",
    "    g_output = g_model(input_z)\n",
    "    images = torch.reshape(g_output,(batch_size, *image_size))\n",
    "    return (images+1)/2\n",
    "\n",
    "epoch_samples = []\n",
    "\n",
    "all_d_losses = []\n",
    "all_g_losses = []\n",
    "\n",
    "all_d_real = []\n",
    "all_d_fake = []\n",
    "\n",
    "num_epochs = 100\n",
    "torch.manual_seed(1)\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    d_losses, g_losses = [], []\n",
    "    d_vals_real, d_vals_fake = [], []\n",
    "    for i, (x, _) in enumerate(mnist_dl):\n",
    "        d_loss, d_proba_real, d_proba_fake = d_train(x)\n",
    "        d_losses.append(d_loss)\n",
    "        g_losses.append(g_train(x))\n",
    "\n",
    "        d_vals_real.append(d_proba_real.mean().cpu())\n",
    "        d_vals_fake.append(d_proba_fake.mean().cpu())\n",
    "\n",
    "    all_d_losses.append(torch.tensor(d_losses).mean())\n",
    "    all_g_losses.append(torch.tensor(g_losses).mean())\n",
    "    all_d_real.append(torch.tensor(d_vals_real).mean())\n",
    "    all_d_fake.append(torch.tensor(d_vals_fake).mean())\n",
    "    print(\n",
    "        f\"Epoch {epoch:03d} | Avg Losses >>\"\n",
    "        f\" G/D {all_g_losses[-1]:.4f}/{all_d_losses[-1]:.4f}\"\n",
    "        f\" [D-Real: {all_d_real[-1]:.4f} D-Fake: {all_d_fake[-1]:.4f}]\"\n",
    "    )\n",
    "    epoch_samples.append(create_samples(gen_model, fixed_z).detach().cpu().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
